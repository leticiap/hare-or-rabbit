{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVNLwf8iLH0y"
      },
      "source": [
        "# Hare or Rabbit?\n",
        "###Projeto desenvolvido em python para classificar se dado animal é um coelho ou uma lebre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6iiA-BKLa9n"
      },
      "outputs": [],
      "source": [
        "# Baixando os arquivos de treinamento e teste\n",
        "\n",
        "!git clone https://github.com/leticiap/hare-or-rabbit.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsXGU_KGN8Eq"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from time import time\n",
        "from torchvision import transforms\n",
        "from torch import nn, optim\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgba2rgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJMyJhemxCHs"
      },
      "outputs": [],
      "source": [
        "# Extraindo as imagens para treinamento\n",
        "\n",
        "now = datetime.now()\n",
        "\n",
        "current_time = now.strftime(\"%H:%M:%S\")\n",
        "print(\"Start Time = \", current_time)\n",
        "train = pd.read_csv('hare-or-rabbit/dataset.csv')\n",
        "train.head()\n",
        "\n",
        "train_img=[]\n",
        "\n",
        "print (\"loading\")\n",
        "for img_name in tqdm(train['image_name']):\n",
        "    img = imread(img_name)\n",
        "    # if we have 4 channels instead of 3\n",
        "    if img.shape[2] != 3:\n",
        "        img = rgba2rgb(img)\n",
        "    img = img.astype('float32')\n",
        "    train_img.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkkR9ltMXgvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2534e5-ec65-47b3-e40b-e9b0c9a85ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting\n",
            "((158, 150, 150, 3), (158,)) ((69, 150, 150, 3), (69,))\n"
          ]
        }
      ],
      "source": [
        "# Conversão de dados, iremos separar 70% das imagens para treino e 30% das imagens para validação (teste)\n",
        "\n",
        "print (\"Converting\")\n",
        "\n",
        "img_size = 150\n",
        "channels = 3\n",
        "train_x = np.array(train_img)\n",
        "train_y = train['label'].values\n",
        "\n",
        "# criando set de validação\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.3)\n",
        "print((train_x.shape, train_y.shape), (val_x.shape, val_y.shape))\n",
        "\n",
        "# convertendo as imagens de treino para o torch\n",
        "train_x = train_x.reshape(train_x.shape[0], 3, img_size, img_size)\n",
        "train_x  = torch.from_numpy(train_x)\n",
        "\n",
        "# convertendo alvos para o torch\n",
        "train_y = train_y.astype(int);\n",
        "train_y = torch.from_numpy(train_y)\n",
        "\n",
        "# convertendo imagens de validação para o torch\n",
        "val_x = val_x.reshape(val_x.shape[0], 3, img_size, img_size)\n",
        "val_x  = torch.from_numpy(val_x)\n",
        "\n",
        "# convertendo alvos para o torch\n",
        "val_y = val_y.astype(int);\n",
        "val_y = torch.from_numpy(val_y)\n",
        "\n",
        "tensor_x = torch.Tensor(train_x) # transformar para o torch tensor\n",
        "tensor_y = torch.Tensor(train_y)\n",
        "\n",
        "my_dataset = TensorDataset(tensor_x,tensor_y) # criando o dataset de treino\n",
        "trainloader = DataLoader(my_dataset) # criando o set de treino\n",
        "\n",
        "tensor_x = torch.Tensor(val_x) # transformando para o torch tensor\n",
        "tensor_y = torch.Tensor(val_y)\n",
        "\n",
        "my_dataset = TensorDataset(tensor_x,tensor_y) # criando o dataset de teste\n",
        "testloader = DataLoader(my_dataset) # criando o set de teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bAqAh5gZC8-"
      },
      "outputs": [],
      "source": [
        "# definição da CNN\n",
        "\n",
        "class Modelo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Modelo, self).__init__()\n",
        "    self.linear1 = nn.Linear(img_size*img_size * channels, 4096) # entrada do tamanho completo da imagem, que se conecta com 4096 neurônios\n",
        "    self.linear2 = nn.Linear(4096, 1024) # camada interna 1,  4096 -> 1024 neurônios, dando o resultado\n",
        "    self.linear3 = nn.Linear(1024, 64) # camada interna 2, 1024 -> 64 neurônios, dando o resultado\n",
        "    self.linear4 = nn.Linear(64, 2) # camada interna 3, 64 -> 2 neurônios, dando o resultado\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.linear1(X))\n",
        "    X = F.relu(self.linear2(X))\n",
        "    X = F.relu(self.linear3(X))\n",
        "    X = self.linear4(X)\n",
        "    return F.log_softmax(X, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4v-Fq8Sb7qj"
      },
      "outputs": [],
      "source": [
        "# Função de treinamento\n",
        "\n",
        "def treino(modelo, trainloader, device):\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)\n",
        "  start = time()\n",
        "\n",
        "  criterio = nn.NLLLoss()\n",
        "  epochs = 10\n",
        "  modelo.train()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    perda_acumulada = 0\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "      imagens = imagens.view(imagens.shape[0], -1)\n",
        "      otimizador.zero_grad()\n",
        "\n",
        "      output = modelo(imagens.to(device))\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device))\n",
        "\n",
        "      perda_instantanea.backward()\n",
        "\n",
        "      otimizador.step()\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item()\n",
        "\n",
        "  print(f\"Training time {(time()-start)/60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWN9hhVYuIdC"
      },
      "outputs": [],
      "source": [
        "# Função de validação\n",
        "def validacao(modelo, valloader, device):\n",
        "  corretos, total = 0, 0\n",
        "  for imagens, etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1, img_size * img_size * channels)\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device))\n",
        "\n",
        "      ps = torch.exp(logps)\n",
        "      probab = list(ps.cpu().numpy()[0])\n",
        "      etiqueta_pred = probab.index(max(probab))\n",
        "      etiqueta_certa = etiquetas.numpy()[i]\n",
        "      if (etiqueta_certa == etiqueta_pred):\n",
        "        corretos += 1\n",
        "      total += 1\n",
        "\n",
        "  print(f\"Total de imagens testadas: {total}\")\n",
        "  print(f\"Precisão do modelo: {corretos*100/total}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqoaO8fc0241",
        "outputId": "dbd59824-c4a8-498d-8591-e83390940b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time 34.51368735631307\n",
            "Total de imagens testadas: 69\n",
            "Precisão do modelo: 53.6231884057971\n"
          ]
        }
      ],
      "source": [
        "# Executando todo o processo da rede (treinar e validar)\n",
        "\n",
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)\n",
        "\n",
        "treino(modelo, trainloader, device)\n",
        "validacao(modelo, testloader, device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}